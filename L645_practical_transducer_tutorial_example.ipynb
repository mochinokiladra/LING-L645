{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BbwgR5UdNkkm"
      },
      "source": [
        "# Transducer implementation in PyTorch\n",
        "\n",
        "*by Loren Lugosch*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yBlJNKsjTtaZ"
      },
      "source": [
        "\n",
        "In this notebook, we will implement a Transducer sequence-to-sequence model for inserting missing vowels into a sentence \n",
        "\n",
        "EX: (\"W wll mplmnt sm cd.\" --> \"We will implement some code.\")\n",
        "*idea: we can change the target sentences to be specific to a domain*\n",
        "\n",
        "\n",
        "Default: (\"Hll, Wrld\" --> \"Hello, World\")."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-iHU02C7fAj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71ffba3a-bbb4-4823-e74d-c0fffe85d10f"
      },
      "source": [
        "import torch\n",
        "import string\n",
        "import numpy as np\n",
        "import itertools\n",
        "from collections import Counter\n",
        "from tqdm import tqdm\n",
        "!pip install unidecode\n",
        "import unidecode\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "DIRECTIONS: Aside from the given training data, find one other open-source data. \n",
        "<15 min>\n",
        "\"\"\"\n",
        "# 1. Default training data.\n",
        "!wget https://raw.githubusercontent.com/lorenlugosch/infer_missing_vowels/master/data/train/war_and_peace.txt\n",
        "!pwd\n",
        "\n",
        "# 2. Find a second training dataset.\n",
        "!wget https://www.gutenberg.org/ebooks/20228.txt.utf-8\n",
        "!mv 20228.txt.utf-8 rizal.txt\n",
        "!pwd"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: unidecode in /usr/local/lib/python3.7/dist-packages (1.3.6)\n",
            "--2022-09-30 23:13:43--  https://raw.githubusercontent.com/lorenlugosch/infer_missing_vowels/master/data/train/war_and_peace.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3196229 (3.0M) [text/plain]\n",
            "Saving to: ‘war_and_peace.txt.11’\n",
            "\n",
            "war_and_peace.txt.1 100%[===================>]   3.05M  --.-KB/s    in 0.01s   \n",
            "\n",
            "2022-09-30 23:13:44 (300 MB/s) - ‘war_and_peace.txt.11’ saved [3196229/3196229]\n",
            "\n",
            "/content\n",
            "--2022-09-30 23:13:44--  https://www.gutenberg.org/ebooks/20228.txt.utf-8\n",
            "Resolving www.gutenberg.org (www.gutenberg.org)... 152.19.134.47, 2610:28:3090:3000:0:bad:cafe:47\n",
            "Connecting to www.gutenberg.org (www.gutenberg.org)|152.19.134.47|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://www.gutenberg.org/cache/epub/20228/pg20228.txt [following]\n",
            "--2022-09-30 23:13:45--  https://www.gutenberg.org/cache/epub/20228/pg20228.txt\n",
            "Reusing existing connection to www.gutenberg.org:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1255442 (1.2M) [text/plain]\n",
            "Saving to: ‘20228.txt.utf-8’\n",
            "\n",
            "20228.txt.utf-8     100%[===================>]   1.20M   853KB/s    in 1.4s    \n",
            "\n",
            "2022-09-30 23:13:47 (853 KB/s) - ‘20228.txt.utf-8’ saved [1255442/1255442]\n",
            "\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTfRgwxmjv1B"
      },
      "source": [
        "# Building blocks\n",
        "\n",
        "First, we will define the encoder, predictor, and joiner using standard neural nets.\n",
        "\n",
        "<img src=\"https://lorenlugosch.github.io/images/transducer/transducer-model.png\" width=\"25%\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7mLFyUG7kJH"
      },
      "source": [
        "\"\"\"\n",
        "RHETORICAL Q: How does changing these numbers affect the performance of the model?\n",
        "In training? In testing? In after-paper performance?\n",
        "\"\"\"\n",
        "NULL_INDEX = 0\n",
        "\n",
        "encoder_dim = 1024\n",
        "predictor_dim = 1024\n",
        "joiner_dim = 1024"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MABMTjrGY4vz"
      },
      "source": [
        "The encoder is any network that can take as input a variable-length sequence: so, RNNs, CNNs, and self-attention/Transformer encoders will all work.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KE7j2T5EY33-"
      },
      "source": [
        "class Encoder(torch.nn.Module):\n",
        "  def __init__(self, num_inputs):\n",
        "    \"\"\"\n",
        "    @num_inputs: the input size/length\n",
        "\n",
        "    DIRECTIONS: complete the variables for the input_size, hidden_size, and bidirectional arguments in self.rnn\n",
        "    <3 min>\n",
        "    \"\"\"\n",
        "    super(Encoder, self).__init__()\n",
        "    self.embed = torch.nn.Embedding(num_inputs, encoder_dim)\n",
        "    self.rnn = torch.nn.GRU(input_size=encoder_dim, hidden_size=encoder_dim, num_layers=3, batch_first=True, bidirectional=True, dropout=0.1)\n",
        "    self.linear = torch.nn.Linear(encoder_dim*2, joiner_dim)\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = x\n",
        "    out = self.embed(out)\n",
        "    out = self.rnn(out)[0]\n",
        "    out = self.linear(out)\n",
        "    return out"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRknN6QRY9-g"
      },
      "source": [
        "The predictor is any _causal_ network (= can't look at the future): in other words, unidirectional RNNs, causal convolutions, or masked self-attention. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPARF5LmY7-r"
      },
      "source": [
        "class Predictor(torch.nn.Module):\n",
        "  def __init__(self, num_outputs):\n",
        "    \"\"\"\n",
        "    @num_outputs: the output size/length\n",
        "\n",
        "    DIRECTIONS: complete the variables for the input_size and hidden_size arguments in self.rnn\n",
        "                complete the arguments to torch.nn.Linear in self.linear (hint: 2 required)\n",
        "    <3 min>\n",
        "    \"\"\"\n",
        "    super(Predictor, self).__init__()\n",
        "    self.embed = torch.nn.Embedding(num_outputs, predictor_dim)\n",
        "    self.rnn = torch.nn.GRUCell(input_size=predictor_dim, hidden_size=predictor_dim)\n",
        "    self.linear = torch.nn.Linear(encoder_dim, joiner_dim)\n",
        "    \n",
        "    self.initial_state = torch.nn.Parameter(torch.randn(predictor_dim))\n",
        "    self.start_symbol = NULL_INDEX # In the original paper, a vector of 0s is used; just using the null index instead is easier when using an Embedding layer.\n",
        "\n",
        "\n",
        "  def forward_one_step(self, input, previous_state):\n",
        "    \"\"\"\n",
        "    This is a helper function for the inherited forward method (since the input may vary).\n",
        "    @input: decoder input\n",
        "    @previous_state: state before passing the input through the RNN's forward method\n",
        "    \"\"\"\n",
        "    embedding = self.embed(input)\n",
        "    state = self.rnn.forward(embedding, previous_state)\n",
        "    out = self.linear(state)\n",
        "    return out, state\n",
        "\n",
        "\n",
        "  def forward(self, y):\n",
        "    \"\"\"\n",
        "    @y: tensor y\n",
        "\n",
        "    DIRECTIONS: complete the variables for batch_size and U (hint: utilize how y is formatted)\n",
        "                complete the variable in the for loop, i.e. replace the 'None'\n",
        "    <5 min>\n",
        "    \"\"\"\n",
        "    batch_size = y.shape[0]\n",
        "    U = y.shape[1]\n",
        "    outs = []\n",
        "    state = torch.stack([self.initial_state] * batch_size).to(y.device)\n",
        "    for u in range(U+1): # hint: we want to get the NULL output for the final timestep \n",
        "      if u == 0:\n",
        "        decoder_input = torch.tensor([self.start_symbol] * batch_size).to(y.device)\n",
        "      else:\n",
        "        decoder_input = y[:,u-1]\n",
        "      out, state = self.forward_one_step(decoder_input, state)\n",
        "      outs.append(out)\n",
        "    out = torch.stack(outs, dim=1)\n",
        "    return out"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHPZ3PATZEAW"
      },
      "source": [
        "The joiner is a feedforward network/MLP with one hidden layer applied independently to each $(t,u)$ index.\n",
        "\n",
        "(The linear part of the hidden layer is contained in the encoder and predictor, so we just do the nonlinearity here and then the output layer.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vlzca1orZDLa"
      },
      "source": [
        "class Joiner(torch.nn.Module):\n",
        "  def __init__(self, num_outputs):\n",
        "    \"\"\"\n",
        "    @num_outputs: size of softmax output over all labels\n",
        "    \"\"\"\n",
        "    super(Joiner, self).__init__()\n",
        "    self.linear = torch.nn.Linear(joiner_dim, num_outputs)\n",
        "\n",
        "  def forward(self, encoder_out, predictor_out):\n",
        "    \"\"\"\n",
        "    @encoder_out: \n",
        "    @predictor_out: \n",
        "\n",
        "    DIRECTIONS:    choose and apply a nonlinear function of your choice\n",
        "    RHETORICAL Q:  why do we add nonlinearity in a neural network?\n",
        "    <5 min>\n",
        "    \"\"\"\n",
        "    out = encoder_out + predictor_out\n",
        "    out = torch.nn.functional.relu(out)\n",
        "    out = self.linear(out)\n",
        "    return out"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "print(torch.cuda.is_available())\n",
        "print(torch.cuda.current_device())\n",
        "print(torch.cuda.get_device_name(0))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oVDYB5ntn-oy",
        "outputId": "fbff089a-ec08-42a1-8b82-2f3bf6279438"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "0\n",
            "Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_-INbhSTApv"
      },
      "source": [
        "# Transducer model + loss function\n",
        "\n",
        "Using the encoder, predictor, and joiner, we will implement the Transducer model and its loss function.\n",
        "\n",
        "<img src=\"https://lorenlugosch.github.io/images/transducer/forward-messages.png\" width=\"25%\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bdcKwA_lkzxJ"
      },
      "source": [
        "We can use a simple PyTorch implementation of the loss function, relying on automatic differentiation to give us gradients."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYSagKi-gHM4"
      },
      "source": [
        "class Transducer(torch.nn.Module):\n",
        "  def __init__(self, num_inputs, num_outputs):\n",
        "    super(Transducer, self).__init__()\n",
        "    self.encoder = Encoder(num_inputs)\n",
        "    self.predictor = Predictor(num_outputs)\n",
        "    self.joiner = Joiner(num_outputs)\n",
        "\n",
        "    if torch.cuda.is_available(): self.device = torch.cuda.current_device()\n",
        "    else: self.device = \"cpu\"\n",
        "    self.to(self.device)\n",
        "\n",
        "  def compute_forward_prob(self, joiner_out, T, U, y):\n",
        "    \"\"\"\n",
        "    @joiner_out: tensor of shape (B, T_max, U_max+1, num_labels)\n",
        "    @T: list of input lengths\n",
        "    @U: list of output lengths \n",
        "    @y: label tensor (B, U_max+1)\n",
        "\n",
        "    DIRECTIONS: draw out a couple iterations of the nested for loop below\n",
        "    <15 min>\n",
        "    \"\"\"\n",
        "    B = joiner_out.shape[0]                                        #B = batch size??\n",
        "    T_max = joiner_out.shape[1]\n",
        "    U_max = joiner_out.shape[2] - 1\n",
        "    log_alpha = torch.zeros(B, T_max, U_max+1).to(model.device)\n",
        "    for t in range(T_max):\n",
        "      for u in range(U_max+1):\n",
        "          if u == 0:\n",
        "            if t == 0:\n",
        "              log_alpha[:, t, u] = 0.\n",
        "\n",
        "            else: #t > 0\n",
        "              log_alpha[:, t, u] = log_alpha[:, t-1, u] + joiner_out[:, t-1, 0, NULL_INDEX] \n",
        "                  \n",
        "          else: #u > 0\n",
        "            if t == 0:\n",
        "              log_alpha[:, t, u] = log_alpha[:, t,u-1] + torch.gather(joiner_out[:, t, u-1], dim=1, index=y[:,u-1].view(-1,1) ).reshape(-1)\n",
        "            \n",
        "            else: #t > 0\n",
        "              log_alpha[:, t, u] = torch.logsumexp(torch.stack([\n",
        "                  log_alpha[:, t-1, u] + joiner_out[:, t-1, u, NULL_INDEX],\n",
        "                  log_alpha[:, t, u-1] + torch.gather(joiner_out[:, t, u-1], dim=1, index=y[:,u-1].view(-1,1) ).reshape(-1)\n",
        "              ]), dim=0)\n",
        "    \n",
        "    log_probs = []\n",
        "    for b in range(B):\n",
        "      log_prob = log_alpha[b, T[b]-1, U[b]] + joiner_out[b, T[b]-1, U[b], NULL_INDEX]\n",
        "      log_probs.append(log_prob)\n",
        "    log_probs = torch.stack(log_probs) \n",
        "    return log_prob # history of logits??\n",
        "\n",
        "  def compute_loss(self, x, y, T, U):\n",
        "    \"\"\"\n",
        "    @x: input/training tensor\n",
        "    @y: label tensor\n",
        "    @T: list of the length of input sequences\n",
        "    @U: list of the length of output sequences\n",
        "    \"\"\"\n",
        "    encoder_out = self.encoder.forward(x)\n",
        "    predictor_out = self.predictor.forward(y)\n",
        "    joiner_out = self.joiner.forward(encoder_out.unsqueeze(2), predictor_out.unsqueeze(1)).log_softmax(3)\n",
        "    loss = -self.compute_forward_prob(joiner_out, T, U, y).mean()\n",
        "    return loss"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IK0c2S2xaARd"
      },
      "source": [
        "Let's first verify that the forward algorithm actually correctly computes the sum (in log space, the [logsumexp](https://lorenlugosch.github.io/posts/2020/06/logsumexp/)) of all possible alignments, using a short input/output pair for which computing all possible alignments is feasible.\n",
        "\n",
        "<img src=\"https://lorenlugosch.github.io/images/transducer/cat-align-1.png\" width=\"25%\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWtkoXH6U8Pm"
      },
      "source": [
        "def compute_single_alignment_prob(self, encoder_out, predictor_out, T, U, z, y):\n",
        "    \"\"\"\n",
        "    Computes the probability of one alignment, z.\n",
        "    @encoder_out: Transducer's self.encoder\n",
        "    @predictor_out: Transducer's self.predictor\n",
        "    @T: list of the length of input sequences\n",
        "    @U: list of the length of output sequences\n",
        "    @z: \n",
        "    @y: label tensor\n",
        "\n",
        "    DIRECTIONS: write a brief description of the argument 'z' above\n",
        "                complete the variables for t_indices and u_indices\n",
        "    <5 min>\n",
        "    \"\"\"\n",
        "    t = 0; u = 0\n",
        "    t_u_indices = []\n",
        "    y_expanded = []\n",
        "    for step in z:\n",
        "      t_u_indices.append((t,u))\n",
        "      if step == 0: # right (null)\n",
        "        y_expanded.append(NULL_INDEX)\n",
        "        t += 1\n",
        "      if step == 1: # down (label)\n",
        "        y_expanded.append(y[u])\n",
        "        u += 1\n",
        "    t_u_indices.append((T-1,U))\n",
        "    y_expanded.append(NULL_INDEX)\n",
        "\n",
        "    t_indices = [t for (t,u) in t_u_indices]\n",
        "    u_indices = [u for (t,u) in t_u_indices]\n",
        "    encoder_out_expanded = encoder_out[t_indices]\n",
        "    predictor_out_expanded = predictor_out[u_indices]\n",
        "    joiner_out = self.joiner.forward(encoder_out_expanded, predictor_out_expanded).log_softmax(1)\n",
        "    logprob = -torch.nn.functional.nll_loss(input=joiner_out, target=torch.tensor(y_expanded).long().to(self.device), reduction=\"sum\")\n",
        "    return logprob\n",
        "\n",
        "Transducer.compute_single_alignment_prob = compute_single_alignment_prob"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8xzM0dZfea9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "512f9e3f-ef7a-44be-8176-54546eb94691"
      },
      "source": [
        "# Generate example inputs/outputs\n",
        "num_outputs = len(string.ascii_uppercase) + 1 # [null, A, B, ... Z]\n",
        "model = Transducer(1, num_outputs)\n",
        "y_letters = \"CAT\"\n",
        "y = torch.tensor([string.ascii_uppercase.index(l) + 1 for l in y_letters]).unsqueeze(0).to(model.device)\n",
        "T = torch.tensor([4]); U = torch.tensor([len(y_letters)]); B = 1\n",
        "\n",
        "encoder_out = torch.randn(B, T, joiner_dim).to(model.device)\n",
        "predictor_out = torch.randn(B, U+1, joiner_dim).to(model.device)\n",
        "joiner_out = model.joiner.forward(encoder_out.unsqueeze(2), predictor_out.unsqueeze(1)).log_softmax(3)\n",
        "\n",
        "#######################################################\n",
        "# Compute loss by enumerating all possible alignments #\n",
        "#######################################################\n",
        "all_permutations = list(itertools.permutations([0]*(T-1) + [1]*U))\n",
        "all_distinct_permutations = list(Counter(all_permutations).keys())\n",
        "alignment_probs = []\n",
        "for z in all_distinct_permutations:\n",
        "  alignment_prob = model.compute_single_alignment_prob(encoder_out[0], predictor_out[0], T.item(), U.item(), z, y[0])\n",
        "  alignment_probs.append(alignment_prob)\n",
        "loss_enumerate = -torch.tensor(alignment_probs).logsumexp(0)\n",
        "\n",
        "#######################################################\n",
        "# Compute loss using the forward algorithm            #\n",
        "#######################################################\n",
        "loss_forward = -model.compute_forward_prob(joiner_out, T, U, y)\n",
        "\n",
        "print(\"Loss computed by enumerating all possible alignments: \", loss_enumerate)\n",
        "print(\"Loss computed using the forward algorithm: \", loss_forward)"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss computed by enumerating all possible alignments:  tensor(19.7130)\n",
            "Loss computed using the forward algorithm:  tensor(19.7130, device='cuda:0', grad_fn=<NegBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WSBAwQONf3z9"
      },
      "source": [
        "Now let's add the greedy search algorithm for predicting an output sequence.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "(Note that I've assumed we're using RNNs for the predictor here. You would have to modify this code a bit if you want to use convolutions/self-attention instead.) \n",
        "<br/><br/>\n",
        "<img src=\"https://lorenlugosch.github.io/images/transducer/greedy-search.png\" width=\"50%\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0xeyb7Jf18_"
      },
      "source": [
        "\"\"\"\n",
        "DIRECTIONS: YOU DO NOT NEED TO IMPLEMENT BEAM SEARCH\n",
        "Here is an *opportunity* to create a beam-search. While the code\n",
        "for a greedy search is here, we can improve this algorithmically! So, you\n",
        "use the greedy search code here to ensure that things are working\n",
        "\n",
        "<might take a while>\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def greedy_search(self, x, T):\n",
        "  y_batch = []\n",
        "  B = len(x)\n",
        "  encoder_out = self.encoder.forward(x)\n",
        "  U_max = 200\n",
        "  for b in range(B):\n",
        "    t = 0; u = 0; y = [self.predictor.start_symbol]; predictor_state = self.predictor.initial_state.unsqueeze(0)\n",
        "    while t < T[b] and u < U_max:\n",
        "      predictor_input = torch.tensor([ y[-1] ]).to(x.device)\n",
        "      g_u, predictor_state = self.predictor.forward_one_step(predictor_input, predictor_state)\n",
        "      f_t = encoder_out[b, t]\n",
        "      h_t_u = self.joiner.forward(f_t, g_u)\n",
        "      argmax = h_t_u.max(-1)[1].item()\n",
        "      if argmax == NULL_INDEX:\n",
        "        t += 1\n",
        "      else: # argmax == a label\n",
        "        u += 1\n",
        "        y.append(argmax)\n",
        "    y_batch.append(y[1:]) # remove start symbol\n",
        "  return y_batch\n",
        "\n",
        "Transducer.greedy_search = greedy_search\n",
        "\n"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhUQMJ-23f2y",
        "outputId": "ceac7fe8-0902-4278-cbb8-d1625d584e78"
      },
      "source": [
        "!pip install speechbrain\n",
        "from speechbrain.nnet.loss.transducer_loss import TransducerLoss\n",
        "transducer_loss = TransducerLoss(0)\n",
        "\n",
        "def compute_loss(self, x, y, T, U):\n",
        "    encoder_out = self.encoder.forward(x)\n",
        "    predictor_out = self.predictor.forward(y)\n",
        "    joiner_out = self.joiner.forward(encoder_out.unsqueeze(2), predictor_out.unsqueeze(1)).log_softmax(3)\n",
        "    #loss = -self.compute_forward_prob(joiner_out, T, U, y).mean()\n",
        "    T = T.to(joiner_out.device)\n",
        "    U = U.to(joiner_out.device)\n",
        "    loss = transducer_loss(joiner_out, y, T, U) #, blank_index=NULL_INDEX, reduction=\"mean\")\n",
        "    return loss\n",
        "\n",
        "Transducer.compute_loss = compute_loss"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: speechbrain in /usr/local/lib/python3.7/dist-packages (0.5.13)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from speechbrain) (1.7.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from speechbrain) (4.64.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.7/dist-packages (from speechbrain) (0.10.0)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.7/dist-packages (from speechbrain) (0.12.1+cu113)\n",
            "Requirement already satisfied: hyperpyyaml in /usr/local/lib/python3.7/dist-packages (from speechbrain) (1.0.1)\n",
            "Requirement already satisfied: torch>=1.9 in /usr/local/lib/python3.7/dist-packages (from speechbrain) (1.12.1+cu113)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from speechbrain) (1.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from speechbrain) (21.3)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from speechbrain) (0.1.97)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from speechbrain) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.9->speechbrain) (4.1.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub->speechbrain) (6.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from huggingface-hub->speechbrain) (4.12.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub->speechbrain) (3.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from huggingface-hub->speechbrain) (2.23.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->speechbrain) (3.0.9)\n",
            "Requirement already satisfied: ruamel.yaml>=0.17.8 in /usr/local/lib/python3.7/dist-packages (from hyperpyyaml->speechbrain) (0.17.21)\n",
            "Requirement already satisfied: ruamel.yaml.clib>=0.2.6 in /usr/local/lib/python3.7/dist-packages (from ruamel.yaml>=0.17.8->hyperpyyaml->speechbrain) (0.2.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->huggingface-hub->speechbrain) (3.8.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub->speechbrain) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub->speechbrain) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub->speechbrain) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub->speechbrain) (2022.6.15)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ff9raB0jVGzN"
      },
      "source": [
        "# Some utilities\n",
        "\n",
        "Here we will add a bit of boilerplate code for training and loading data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5b17OQm4WdVy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "296523b6-6b58-4564-d4c4-3809da0679ed"
      },
      "source": [
        "class TextDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, lines, batch_size):\n",
        "    \"\"\"\n",
        "    @lines: list of strings\n",
        "    \"\"\"\n",
        "    lines = list(filter((\"\\n\").__ne__, lines))\n",
        "\n",
        "    self.lines = lines \n",
        "    collate = Collate()\n",
        "    self.loader = torch.utils.data.DataLoader(self, batch_size=batch_size, num_workers=1, shuffle=True, collate_fn=collate)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.lines)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    line = self.lines[idx].replace(\"\\n\", \"\")\n",
        "    line = unidecode.unidecode(line) # remove special characters\n",
        "    x = \"\".join(c for c in line if c not in \"AEIOUaeiou\") # remove vowels from input\n",
        "    y = line\n",
        "    return (x,y)\n",
        "\n",
        "def encode_string(s):\n",
        "  \"\"\"\n",
        "  @s: string\n",
        "  \"\"\"\n",
        "  for c in s:\n",
        "    if c not in string.printable:\n",
        "      print(s)\n",
        "  return [string.printable.index(c) + 1 for c in s]\n",
        "\n",
        "def decode_labels(l):\n",
        "  \"\"\"\n",
        "  @l: list of labels\n",
        "  \"\"\"\n",
        "  return \"\".join([string.printable[c - 1] for c in l])\n",
        "\n",
        "\n",
        "class Collate:\n",
        "  def __call__(self, batch):\n",
        "    \"\"\"\n",
        "    Returns a minibatch of strings, encoded as labels and padded to have the same length.\n",
        "    @batch: list of tuples (input string, output string)\n",
        "\n",
        "    DIRECTIONS: after obtaining results from training on the default text, train on your second training text \n",
        "    <10 min>\n",
        "    \"\"\"\n",
        "    x = []; y = []\n",
        "    batch_size = len(batch)\n",
        "    for index in range(batch_size):\n",
        "      x_,y_ = batch[index]\n",
        "      x.append(encode_string(x_))\n",
        "      y.append(encode_string(y_))\n",
        "\n",
        "    # pad all sequences to have same length\n",
        "    T = [len(x_) for x_ in x]\n",
        "    U = [len(y_) for y_ in y]\n",
        "    T_max = max(T)\n",
        "    U_max = max(U)\n",
        "    for index in range(batch_size):\n",
        "      x[index] += [NULL_INDEX] * (T_max - len(x[index]))\n",
        "      x[index] = torch.tensor(x[index])\n",
        "      y[index] += [NULL_INDEX] * (U_max - len(y[index]))\n",
        "      y[index] = torch.tensor(y[index])\n",
        "\n",
        "    # stack into single tensor\n",
        "    x = torch.stack(x)\n",
        "    y = torch.stack(y)\n",
        "    T = torch.tensor(T)\n",
        "    U = torch.tensor(U)\n",
        "\n",
        "    return (x,y,T,U)\n",
        "\n",
        "with open(\"rizal.txt\", \"r\") as f:\n",
        "  lines = f.readlines()\n",
        "\n",
        "end = round(0.9 * len(lines))\n",
        "train_lines = lines[:end]\n",
        "test_lines = lines[end:]\n",
        "train_set = TextDataset(train_lines, batch_size=64) #8)\n",
        "test_set = TextDataset(test_lines, batch_size=64) #8)\n",
        "train_set.__getitem__(0)"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Th Prjct Gtnbrg Bk f Nl M Tngr, by Js Rzl',\n",
              " 'The Project Gutenberg EBook of Noli Me Tangere, by Jose Rizal')"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gaZEQYzfFEQ0"
      },
      "source": [
        "class Trainer:\n",
        "  def __init__(self, model, lr):\n",
        "    self.model = model\n",
        "    self.lr = lr\n",
        "    self.optimizer = torch.optim.Adam(model.parameters(), lr=self.lr)\n",
        "  \n",
        "  def train(self, dataset, print_interval = 20):\n",
        "    train_loss = 0\n",
        "    num_samples = 0\n",
        "    self.model.train()\n",
        "    pbar = tqdm(dataset.loader)\n",
        "    for idx, batch in enumerate(pbar):\n",
        "      x,y,T,U = batch\n",
        "      x = x.to(self.model.device); y = y.to(self.model.device)\n",
        "      batch_size = len(x)\n",
        "      num_samples += batch_size\n",
        "      loss = self.model.compute_loss(x,y,T,U)\n",
        "      self.optimizer.zero_grad()\n",
        "      pbar.set_description(\"%.2f\" % loss.item())\n",
        "      loss.backward()\n",
        "      self.optimizer.step()\n",
        "      train_loss += loss.item() * batch_size\n",
        "      if idx % print_interval == 0:\n",
        "        self.model.eval()\n",
        "        guesses = self.model.greedy_search(x,T)\n",
        "        self.model.train()\n",
        "        print(\"\\n\")\n",
        "        for b in range(2):\n",
        "          print(\"input:\", decode_labels(x[b,:T[b]]))\n",
        "          print(\"guess:\", decode_labels(guesses[b]))\n",
        "          print(\"truth:\", decode_labels(y[b,:U[b]]))\n",
        "          print(\"\")\n",
        "    train_loss /= num_samples\n",
        "    return train_loss\n",
        "\n",
        "  def test(self, dataset, print_interval=1):\n",
        "    test_loss = 0\n",
        "    num_samples = 0\n",
        "    self.model.eval()\n",
        "    pbar = tqdm(dataset.loader)\n",
        "    for idx, batch in enumerate(pbar):\n",
        "      x,y,T,U = batch\n",
        "      x = x.to(self.model.device); y = y.to(self.model.device)\n",
        "      batch_size = len(x)\n",
        "      num_samples += batch_size\n",
        "      loss = self.model.compute_loss(x,y,T,U)\n",
        "      pbar.set_description(\"%.2f\" % loss.item())\n",
        "      test_loss += loss.item() * batch_size\n",
        "      if idx % print_interval == 0:\n",
        "        print(\"\\n\")\n",
        "        print(\"input:\", decode_labels(x[0,:T[0]]))\n",
        "        print(\"guess:\", decode_labels(self.model.greedy_search(x,T)[0]))\n",
        "        print(\"truth:\", decode_labels(y[0,:U[0]]))\n",
        "        print(\"\")\n",
        "    test_loss /= num_samples\n",
        "    return test_loss\n",
        "    "
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4PupgBKWe6p"
      },
      "source": [
        "# Training the model\n",
        "\n",
        "Now we will train a model. This will generate some output sequences every 20 batches."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1TSrbH9xGPEC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd808e0c-7f5e-44d4-f402-e4c4f1839cb8"
      },
      "source": [
        "num_chars = len(string.printable)\n",
        "model = Transducer(num_inputs=num_chars+1, num_outputs=num_chars+1)\n",
        "trainer = Trainer(model=model, lr=0.0003)\n",
        "\n",
        "num_epochs = 1\n",
        "train_losses=[]\n",
        "test_losses=[]\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss = trainer.train(train_set)\n",
        "    test_loss = trainer.test(test_set)\n",
        "    train_losses.append(train_loss)\n",
        "    test_losses.append(test_loss)\n",
        "    print(\"Epoch %d: train loss = %f, test loss = %f\" % (epoch, train_loss, test_loss))"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "413.28:   0%|          | 1/270 [00:23<1:46:21, 23.72s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "input: knttln n~g dyng png-gyn s snggl n llk. ng\n",
            "guess: \n",
            "truth: kinatatalian n~g duyang pinag-uuguyan sa sanggol na lalaki. Ang\n",
            "\n",
            "input: Mpnglw t ng-sp-sp n~g sy'y msmpng n~g Cptn Gnrl.\n",
            "guess: \n",
            "truth: Mapanglaw at nag-iisip-isip n~g siya'y masumpong n~g Capitan General.\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "190.40:   8%|▊         | 21/270 [07:59<1:38:29, 23.73s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "input: clgyn t hnd c mnglng n c'y mnglpypy: bnnt cng\n",
            "guess: a\n",
            "truth: calagayan at hindi co minagaling na aco'y manglupaypay: binanta cong\n",
            "\n",
            "input: c rn ng cmcn!--ng sngt nt n~g gyn dn ny n~g\n",
            "guess: a\n",
            "truth: aco rin ang cumacain!--ang isinagot nito n~g gayon din anyo n~g\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "165.58:  15%|█▌        | 41/270 [15:39<1:33:26, 24.48s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "input: bng clptn n~g trbnl n~g nqscng ngprtng n sy'y\n",
            "guess: n~g cang cang cang cang cang cang cang cang cang cang cang cang cang cang cang cang cang cang cang cang cang cang cang cang cang cang cang cang cang cang cang cang cang cang cang cang cang cang cang c\n",
            "truth: boong calupitan n~g tribunal n~g Inquisiciong nagparatang na siya'y\n",
            "\n",
            "input: mcgy'y blgtd ng bbn~g n~g nyng lht n m~g pgppgl:\n",
            "guess: nang cang cang cang cang cang cang cang cang cang cang cang cang cang cang cang cang cang cang cang cang cang cang cang cang cang cang cang cang cang cang cang cang cang cang cang cang cang cang cang \n",
            "truth: macagayo'y baligtad ang ibubun~ga n~g inyong lahat na m~ga pagpapagal:\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "157.31:  23%|██▎       | 61/270 [23:21<1:25:42, 24.60s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "input: Tnwg n~g Cptn Gnrl ng cnyng ydnt.\n",
            "guess: nang cang cang cang cang cang cang cang cang cang cang cang cang cang cang cang cang cang cang cang cang cang cang cang cang cang cang cang cang cang cang cang cang cang cang cang cang cang cang cang \n",
            "truth: Tinawag n~g Capitan General ang canyang ayudante.\n",
            "\n",
            "input: hmhdlng s pgsss, t spgc't mlk ng chgtn n~g tlsn\n",
            "guess: --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "truth: humahadlang sa pagsisisi, at sapagca't malaki ang cahigtan n~g tulisan\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "165.39:  30%|███       | 81/270 [31:06<1:17:56, 24.75s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "input: s kn, cng d c sn ngsnn~glng n~g cw y tnttnng c.\n",
            "guess: nang mang mang mang mang mang mang mang mang mang mang mang mang mang mang mang mang mang mang mang mang mang mang mang mang mang mang mang mang mang mang mang mang mang mang mang mang mang mang mang \n",
            "truth: sa akin, cung di ca sana nagsinun~galing n~g icaw ay tinatatanong co.\n",
            "\n",
            "input: n tg bng lpn, n tntcpn ntn n~g pgc ndlntng t ng\n",
            "guess: nang mang mang mang mang mang mang mang mang mang mang mang mang mang mang mang mang mang mang mang mang mang mang mang mang mang mang mang mang mang mang mang mang mang mang mang mang mang mang mang \n",
            "truth: na taga ibang lupain, na tinatacpan natin n~g pagca indolenteng ito ang\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "133.92:  37%|███▋      | 101/270 [38:51<1:09:00, 24.50s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "input: s cmy n Mr Cr, n pmsc n hls hnd mchcbng t kmng\n",
            "guess: nang na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na \n",
            "truth: sa camay ni Maria Ciara, na pumasoc na halos hindi macahacbang at kiming\n",
            "\n",
            "input: lp't hnpn nny rn ng bng gntng tng kncln~gn!\n",
            "guess: nang na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na \n",
            "truth: lupai't hanapin ninyo roon ang ibang guintong ating kinacailan~gan!\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "128.79:  45%|████▍     | 121/270 [46:29<1:00:07, 24.21s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "input: pgsscpn n n~g yng m~g nc n hmrp t sspt ng slpng\n",
            "guess: inagpagang pagpagang pagpagang pagpagang pagpagang pagpagang pagpagang pagpagang pagpagang pagpagang pagpagang pagpagang pagpagang pagpagang pagpagang pagpagang pagpagang pagpagang pagpagang pagpagang\n",
            "truth: pagsisicapan na n~g iyong m~ga anac na humarap at isisipot ang salaping\n",
            "\n",
            "input: knllgyn n~g spn t Prtgl.\n",
            "guess: inang canyang canyang canyang canyang canyang canyang canyang canyang canyang canyang canyang canyang canyang canyang canyang canyang canyang canyang canyang canyang canyang canyang canyang canyang ca\n",
            "truth: kinalalagyan n~g Espana at Portugal.\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "143.25:  52%|█████▏    | 141/270 [54:03<50:42, 23.59s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "input: =XLX.=\n",
            "guess: ----ang m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~\n",
            "truth: =XLIX.=\n",
            "\n",
            "input: pnghgnt c cy s pmmg-tn n~g py, n~g dg t n~g kng\n",
            "guess: n~g m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m\n",
            "truth: ipanghiganti co cayo sa pamamag-itan n~g apoy, n~g dugo at n~g aking\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "102.54:  60%|█████▉    | 161/270 [1:01:42<43:43, 24.07s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "input: hnd tglg, hnd ltn, hnd nsc t b p. ?ng m~g frl cy\n",
            "guess: nananang mang mang mang mang mang mang mang mang mang mang mang mang mang mang mang mang mang mang mang mang mang mang mang mang mang mang mang mang mang mang mang mang mang mang mang mang mang mang m\n",
            "truth: hindi tagalog, hindi latin, hindi insic at iba pa. ?Ang m~ga fraile caya\n",
            "\n",
            "input: --?S cl m cy?--ng tnng n~g mlt n ngttc.--Sbhn mng\n",
            "guess: ----ang magang magang magang magang magang magang magang magang magang magang magang magang magang magang magang magang magang magang magang magang magang magang magang magang magang magang magang mag\n",
            "truth: --?Sa acala mo caya?--ang tanong n~g maliit na nagtataca.--Sabihin mong\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "140.26:  67%|██████▋   | 181/270 [1:09:19<35:25, 23.88s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "input: dlg ng m~g tlbs n~g clbz, hnhmy ng m~g ptn t\n",
            "guess: mang m~ga casang m~ga casang m~ga casang m~ga casang m~ga casang m~ga casang m~ga casang m~ga casang m~ga casang m~ga casang m~ga casang m~ga casang m~ga casang m~ga casang m~ga casang m~ga casang m~g\n",
            "truth: dalaga ang m~ga talbos n~g calabaza, hinihimay ang m~ga patani at\n",
            "\n",
            "input: ?bkt? Dyt't ?hnd n~g cy mngyyrng mgcys ng pgsnt s\n",
            "guess: malalang m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m\n",
            "truth: ?bakit? Diyata't ?hindi n~ga caya mangyayaring magcaayos ang pagsinta sa\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "128.69:  74%|███████▍  | 201/270 [1:17:05<27:48, 24.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "input: Hnpls n brr ng cnyng n.\n",
            "guess: pagpagpagpagpagpagpagpagpagpagpagpagpagpagpagaling sa sa sa sa sa sa sa sa sa sa sa sa sa sa sa sa sa sa sa sa sa sa sa sa sa sa sa sa sa sa sa sa sa sa sa sa sa sa sa sa sa sa sa sa sa sa sa sa sa sa\n",
            "truth: Hinaplos ni Ibarra ang canyang noo.\n",
            "\n",
            "input: N~g mclmps ng sndlng hnd pg-mc n gnmt n ls s\n",
            "guess: m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga \n",
            "truth: N~g macalampas ang sandaling hindi pag-imic na guinamit ni Elias sa\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "88.75:  82%|████████▏ | 221/270 [1:24:34<19:06, 23.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "input: --?Bkt cy myc? _?bnm gntm sms?_[264]\n",
            "guess: ---ang ang ang ang ang ang ang ang ang ang ang ang ang ang ang ang ang ang ang ang ang ang ang ang ang ang ang ang ang ang ang ang ang ang ang ang ang ang ang ang ang ang ang ang ang ang ang ang ang a\n",
            "truth: --?Bakit cayo umiiyac? _?Ubinam gentium sumus?_[264]\n",
            "\n",
            "input: Smntlng nngyyr t'y sy nmng pgdtng n cptng Tg n\n",
            "guess: ang canyang canyang canyang canyang canyang canyang canyang canyang canyang canyang canyang canyang canyang canyang canyang canyang canyang canyang canyang canyang canyang canyang canyang canyang cany\n",
            "truth: Samantalang nangyayari ito'y siya namang pagdating ni capitang Tiago na\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "126.42:  89%|████████▉ | 241/270 [1:32:06<11:31, 23.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "input: bhl:\n",
            "guess: --!an~ga\n",
            "truth: bahala:\n",
            "\n",
            "input: chlhlhng mgsysy. Bcd s rt'y ng m~g bgy n ssbhn\n",
            "guess: --!ang cabala\n",
            "truth: cahulihulihang magsaysay. Bucod sa rito'y ang m~ga bagay na sasabihin\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "137.00:  97%|█████████▋| 261/270 [1:39:38<03:24, 22.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "input: n nnggglng s mts, pgdtng s bb'y nwwl-ng cblhn,\n",
            "guess: nan~gang nan~ganga\n",
            "truth: na nanggagaling sa mataas, pagdating sa baba'y nawawal-ang cabuluhan,\n",
            "\n",
            "input: m'y kklnln s cnyng tng n lb!\"\n",
            "guess: nalalang nalalang nalan\n",
            "truth: ma'y kikilanlin sa canyang utang na loob!\"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "140.81: 100%|██████████| 270/270 [1:42:46<00:00, 22.84s/it]\n",
            "20.41:   0%|          | 0/29 [00:01<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "input: --?Sn cy ng hrj n s rw n~g fst'y ngccn~gn? Cy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r20.41:   3%|▎         | 1/29 [00:03<01:43,  3.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "guess: --!--!--ang-angangan\n",
            "truth: --?Sino caya ang hereje na sa araw n~g fiesta'y nagcacain~gin? Caya\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r114.20:   3%|▎         | 1/29 [00:04<01:43,  3.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "input: Hmhp n~g bng glt ng bgy hls s mgdmg; hnd smct ng\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r114.20:   7%|▋         | 2/29 [00:07<01:42,  3.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "guess: --ang m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga\n",
            "truth: Humihip n~g boong galit ang bagyo halos sa magdamag; hindi sumicat ang\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r294.86:   7%|▋         | 2/29 [00:08<01:42,  3.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "input: mw s cnyng bhy s cptng Tnng n my skt, ptln t\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r294.86:  10%|█         | 3/29 [00:10<01:32,  3.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "guess: cananganga\n",
            "truth: Umuwi sa canyang bahay si capitang Tinong na may sakit, putlain at\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r147.05:  10%|█         | 3/29 [00:11<01:32,  3.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "input: nng pltn c n~g yng slt ..., d mn'y n~g sy rw y\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r147.05:  14%|█▍        | 4/29 [00:14<01:29,  3.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "guess: nan~ga\n",
            "truth: nang palitan co n~g iyong sulat ..., di umano'y n~g siya raw ay\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r119.84:  14%|█▍        | 4/29 [00:15<01:29,  3.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "input: Nggplng ng cdd, wlng nrrn~gg n mncnc cng d ng\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r119.84:  17%|█▋        | 5/29 [00:17<01:24,  3.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "guess: --!pagcapan~gan n~gan~ga\n",
            "truth: Nagugupiling ang ciudad, walang naririn~gig na manacanaca cung di ang\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r117.24:  17%|█▋        | 5/29 [00:19<01:24,  3.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "input: cglhn.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r117.24:  21%|██        | 6/29 [00:21<01:23,  3.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "guess: --angala\n",
            "truth: caguluhan.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r105.34:  21%|██        | 6/29 [00:22<01:23,  3.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "input: nlss y cmply wth prgrph 1..8 r 1..9.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r105.34:  24%|██▍       | 7/29 [00:25<01:20,  3.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "guess: calalat at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at \n",
            "truth: unless you comply with paragraph 1.E.8 or 1.E.9.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r88.99:  24%|██▍       | 7/29 [00:26<01:20,  3.64s/it] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "input: t snng ng m~g lbrng wlng cnn mng csmn, n snlt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r88.99:  28%|██▊       | 8/29 [00:28<01:13,  3.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "guess: ang matang at nanganga\n",
            "truth: At sinunog ang m~ga librong walang caanoano mang casamaan, na sinulat\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r187.94:  28%|██▊       | 8/29 [00:29<01:13,  3.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "input: cstl't nsc lmng ng cnyng m~g nnyyhn; tngcl s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r187.94:  31%|███       | 9/29 [00:32<01:11,  3.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "guess: calalangangangang matamat at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at \n",
            "truth: castila't insic lamang ang canyang m~ga inanyayahan; tungcol sa\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r121.12:  31%|███       | 9/29 [00:33<01:11,  3.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "input: lmng c s pgtn~gs s pgdrlt nmng lht, n nsn n~g\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r121.12:  34%|███▍      | 10/29 [00:36<01:08,  3.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "guess: calalang calalang calalang calalang calalang calalang calalang calalang calalang calalang calalang calalang calalang calalang calalang calalang calalang calalang calalang calalang calalang calalang ca\n",
            "truth: lamang aco sa pagtan~gis sa pagdaralita naming lahat, na inisin n~g\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r130.00:  34%|███▍      | 10/29 [00:37<01:08,  3.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "input: kng ps. kng pnhmc cw pnhmc c ng kng snt.... ?n\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r130.00:  38%|███▊      | 11/29 [00:39<01:03,  3.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "guess: caningan\n",
            "truth: aking puso. Aking ipinahamac icaw ipinahamac co ang aking sinta.... ?ano\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r98.59:  38%|███▊      | 11/29 [00:40<01:03,  3.52s/it] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "input: Gtnbrg Ltrry rchv Fndtn, th wnr f th Prjct\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r98.59:  41%|████▏     | 12/29 [00:42<00:59,  3.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "guess: at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at\n",
            "truth: Gutenberg Literary Archive Foundation, the owner of the Project\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r326.73:  41%|████▏     | 12/29 [00:43<00:59,  3.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "input: llkng ncscy s bngcng yn y pmnhc s hgdnng bt,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r326.73:  45%|████▍     | 13/29 [00:46<00:56,  3.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "guess: calalalanganganga\n",
            "truth: lalaking nacasacay sa bangcang iyon ay pumanhic sa hagdanang bato,\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r78.27:  45%|████▍     | 13/29 [00:47<00:56,  3.52s/it] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "input: Sctn  2.  nfrmtn bt th Mssn f Prjct Gtnbrg-tm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r78.27:  48%|████▊     | 14/29 [00:49<00:52,  3.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "guess: catang atanga\n",
            "truth: Section  2.  Information about the Mission of Project Gutenberg-tm\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r103.86:  48%|████▊     | 14/29 [00:50<00:52,  3.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "input: cpnglwn.--Knh c s blnggng png bsn~gn s kn n~g kng\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r103.86:  52%|█████▏    | 15/29 [00:52<00:47,  3.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "guess: calangan~gang\n",
            "truth: capanglawan.--Kinuha aco sa bilangguang pinag absan~gan sa akin n~g aking\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r115.21:  52%|█████▏    | 15/29 [00:53<00:47,  3.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "input: sy'y cnyng nkt s cnyng hrp ng sng t n pngmmsdn\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r115.21:  55%|█████▌    | 16/29 [00:56<00:44,  3.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "guess: cangangangan\n",
            "truth: siya'y canyang nakita sa canyang harap ang isang tao na pinagmamasdan\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r120.55:  55%|█████▌    | 16/29 [00:57<00:44,  3.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "input: nbg nny ng knmltn nnyng byn, cwn~gs n~g tng\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r120.55:  59%|█████▊    | 17/29 [00:59<00:41,  3.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "guess: nan~gan n~g caningan~gangan~gan~gan\n",
            "truth: iniibig ninyo ang kinamulatan ninyong bayan, cawan~gis n~g ating\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r285.72:  59%|█████▊    | 17/29 [01:01<00:41,  3.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "input: ntpl, n~g Vrgn dl Rsr,  cng hnd m'y n~g Vrgn dl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r285.72:  62%|██████▏   | 18/29 [01:03<00:37,  3.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "guess: capatang at nan~ga\n",
            "truth: Antipolo, n~g Virgen del Rosario, o cung hindi ma'y n~g Virgen del\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r114.55:  62%|██████▏   | 18/29 [01:04<00:37,  3.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "input: lmn~gn t ng-clng tmcs, n~gn't ngpthlg s chy ng\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r114.55:  66%|██████▌   | 19/29 [01:06<00:33,  3.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "guess: nan~gangangan\n",
            "truth: lumin~gon at nag-acalang tumacas, n~guni't nagpatihulog sa cahoy ang\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r107.40:  66%|██████▌   | 19/29 [01:07<00:33,  3.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "input: m~g tn~gng gnng tmtwg s cnlng srl n~g <<cvlzd>>.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r107.40:  69%|██████▉   | 20/29 [01:10<00:30,  3.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "guess: --ang m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga m~ga\n",
            "truth: m~ga tan~ging guinoong tumatawag sa canilang sarili n~g <<civilizado>>.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r104.90:  69%|██████▉   | 20/29 [01:11<00:30,  3.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "input: --Hl n ty,--ng bnlng n nmmtl.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r104.90:  72%|███████▏  | 21/29 [01:13<00:27,  3.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "guess: --!angalangan\n",
            "truth: --Huli na tayo,--ang ibinulong na namumutla.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r125.01:  72%|███████▏  | 21/29 [01:14<00:27,  3.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "input: mt, n smsnd s ny n~g rg nyng n.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r125.01:  76%|███████▌  | 22/29 [01:17<00:24,  3.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "guess: ang matan nan nan~gangan\n",
            "truth: mata, na sumusunod sa anyo n~g irog niyang ina.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r305.58:  76%|███████▌  | 22/29 [01:18<00:24,  3.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "input:      wd t th wnr f th Prjct Gtnbrg-tm trdmrk, bt h\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r305.58:  79%|███████▉  | 23/29 [01:20<00:20,  3.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "guess: --ang at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at\n",
            "truth:      owed to the owner of the Project Gutenberg-tm trademark, but he\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r283.78:  79%|███████▉  | 23/29 [01:21<00:20,  3.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "input: cphmcn; t cng cncnn ng m~g ht t m~g cmy n smbg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r283.78:  83%|████████▎ | 24/29 [01:23<00:17,  3.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "guess: --!canganga\n",
            "truth: capahamacan; at cung canicanino ang m~ga hita at m~ga camay na sumabog\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r99.87:  83%|████████▎ | 24/29 [01:24<00:17,  3.46s/it] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "input: cmtyn? !Wl n n~gng nllb s kn cng hnd ng pgtts,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r99.87:  86%|████████▌ | 25/29 [01:27<00:13,  3.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "guess: canganganganga\n",
            "truth: camatayan? !Wala na n~gang nalalabi sa akin cung hindi ang pagtitiis,\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r13.57:  86%|████████▌ | 25/29 [01:28<00:13,  3.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "input: lmn ng bngc, t wlng n mng dndlt n sct nyng\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r13.57:  90%|████████▉ | 26/29 [01:30<00:10,  3.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "guess: calalang nangan~gan\n",
            "truth: laman ang bangca, at walang ano mang idinudulot na sucat niyang\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r123.75:  90%|████████▉ | 26/29 [01:31<00:10,  3.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "input: --?Nkt n nny?--n ls, t nlgy s bngc ng\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r123.75:  93%|█████████▎| 27/29 [01:34<00:07,  3.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "guess: --!--!at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at\n",
            "truth: --?Nakita na ninyo?--ani Elias, at inilagay sa bangca ang\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r100.07:  93%|█████████▎| 27/29 [01:35<00:07,  3.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "input: Tnngnn sy n t sbl n ngglt.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r100.07:  97%|█████████▋| 28/29 [01:38<00:03,  3.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "guess: nan~gan nan~gan nanga\n",
            "truth: Tiningnan siya ni tia Isabel na nagugulat.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r227.64:  97%|█████████▋| 28/29 [01:39<00:03,  3.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "input: --yn n~g ng smssp c; tnmn nny ng sgt.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "227.64: 100%|██████████| 29/29 [01:41<00:00,  3.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "guess: --!--!--anganganga\n",
            "truth: --Iyan n~ga ang sumasaisip co; tinamaan ninyo ang sugat.\n",
            "\n",
            "Epoch 0: train loss = 134.123707, test loss = 144.209132\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRahAWPoubyu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c3eb277-2df3-418b-da6e-b2049fe33aae"
      },
      "source": [
        "print(train_losses)\n",
        "print(test_losses)"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[134.1237073446313]\n",
            "[144.20913219451904]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLQKw4kmFj3S"
      },
      "source": [
        "Let's test the model on a new sentence:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zhH5lYdyEazJ",
        "outputId": "bcd86b69-999b-4fb3-8d8d-ef845b476749"
      },
      "source": [
        "\"\"\"\n",
        "DIRECTIONS: Experiment with different test outputs. What are some things to keep in mind when changing the test outputs?\n",
        "<5 min>\n",
        "\"\"\"\n",
        "\n",
        "test_output = \"Umakyat ako sa jeep ni Tatay at umupo sa tabi niya.\"\n",
        "test_input = \"\".join(c for c in test_output if c not in \"AEIOUaeiou\")\n",
        "print(\"input: \" + test_input)\n",
        "x = torch.tensor(encode_string(test_input)).unsqueeze(0).to(model.device)\n",
        "y = torch.tensor(encode_string(test_output)).unsqueeze(0).to(model.device)\n",
        "T = torch.tensor([x.shape[1]]).to(model.device)\n",
        "U = torch.tensor([y.shape[1]]).to(model.device)\n",
        "guess = model.greedy_search(x,T)[0]\n",
        "print(\"truth: \" + test_output)\n",
        "print(\"guess: \" + decode_labels(guess))\n",
        "print(\"\")\n",
        "y_guess = torch.tensor(guess).unsqueeze(0).to(model.device)\n",
        "U_guess = torch.tensor(len(guess)).unsqueeze(0).to(model.device)\n",
        "\n",
        "print(\"NLL of truth: \" + str(model.compute_loss(x, y, T, U)))\n",
        "print(\"NLL of guess: \" + str(model.compute_loss(x, y_guess, T, U_guess)))"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input: mkyt k s jp n Tty t mp s tb ny.\n",
            "truth: Umakyat ako sa jeep ni Tatay at umupo sa tabi niya.\n",
            "guess: at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at\n",
            "\n",
            "NLL of truth: tensor(127.5484, device='cuda:0', grad_fn=<NegBackward0>)\n",
            "NLL of guess: tensor(147.4962, device='cuda:0', grad_fn=<NegBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ET__-ItZD8eA"
      },
      "source": [
        "Observe that the negative log-likelihood of the guess is actually worse than that of the true label sequence (AKA, a \"[search error](https://www.aclweb.org/anthology/D19-1331.pdf)\"). This suggests that we could get better results using a beam search instead of the greedy search."
      ]
    }
  ]
}